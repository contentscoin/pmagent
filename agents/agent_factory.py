#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ì—ì´ì „íŠ¸ íŒ©í† ë¦¬

ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” íŒ©í† ë¦¬ íŒ¨í„´ êµ¬í˜„
"""

import os
import json
import re
import requests
import sys
from typing import Dict, Any, Optional, List, Union, Tuple

# ê²½ë¡œ ì„¤ì • - í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from .frontend_agent_ollama import FrontendAgentOllama
from .backend_agent_ollama import BackendAgentOllama
from .pm_agent_ollama import PMAgentOllama
from .designer_agent_ollama import DesignerAgentOllama
from .ai_engineer_agent_ollama import AIEngineerAgentOllama
from .mcp_agent_helper import MCPAgentHelper

try:
    MCP_AVAILABLE = True
except ImportError:
    MCP_AVAILABLE = False

class AgentFactory:
    """
    ì—ì´ì „íŠ¸ íŒ©í† ë¦¬ í´ë˜ìŠ¤
    
    ë‹¤ì–‘í•œ íƒ€ì…ì˜ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•˜ê³  ê´€ë¦¬í•˜ëŠ” íŒ©í† ë¦¬ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    í™˜ê²½ ë³€ìˆ˜ ê¸°ë°˜ ì„¤ì •, íŒŒì¼ ê¸°ë°˜ ì„¤ì •ì„ ì§€ì›í•˜ë©° ì—ì´ì „íŠ¸ ìºì‹± ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    PM ì—ì´ì „íŠ¸ì— ë‹¤ë¥¸ ì—ì´ì „íŠ¸ë“¤ì„ ìë™ìœ¼ë¡œ ë“±ë¡í•˜ì—¬ ì¤‘ì•™ ê´€ë¦¬ ì²´ê³„ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """
        AgentFactory ì´ˆê¸°í™”
        
        Args:
            config_path (Optional[str]): ì„¤ì • íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: None)
        """
        # ì—ì´ì „íŠ¸ ìºì‹œ
        self.cache = {}
        # ì„¤ì •
        self.config = {}
        # ì„¤ì • íŒŒì¼ ë¡œë“œ (ì œê³µëœ ê²½ìš°)
        if config_path:
            self.config = self.load_config(config_path)
        
        # ëª¨ë¸ ê°€ìš©ì„± ìºì‹œ
        self.available_models_cache = None
    
    def load_config(self, config_path: str) -> Dict[str, Any]:
        """
        ì„¤ì • íŒŒì¼ ë¡œë“œ
        
        Args:
            config_path (str): ì„¤ì • íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Dict[str, Any]: ë¡œë“œëœ ì„¤ì •
            
        Raises:
            ValueError: ì„¤ì • íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì½ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
        """
        if not os.path.exists(config_path):
            raise ValueError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
        
        try:
            with open(config_path, "r") as f:
                config = json.load(f)
            
            # í™˜ê²½ ë³€ìˆ˜ ëŒ€ì²´
            config_str = json.dumps(config)
            env_pattern = re.compile(r'\${([^}]+)}')
            
            def replace_env_var(match):
                env_var = match.group(1)
                return os.environ.get(env_var, "")
            
            config_str = env_pattern.sub(replace_env_var, config_str)
            config = json.loads(config_str)
            
            return config
        except Exception as e:
            raise ValueError(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    def get_api_key(self, agent_type: str = None) -> str:
        """
        ì—ì´ì „íŠ¸ ìœ í˜•ì— ë§ëŠ” API í‚¤ ë°˜í™˜
        
        Args:
            agent_type (str, optional): ì—ì´ì „íŠ¸ ìœ í˜•
            
        Returns:
            str: API í‚¤
        """
        # ì„¤ì •ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
        if self.config and "agents" in self.config:
            agents_config = self.config["agents"]
            provider = agents_config.get("provider", "ollama")
            
            if "api_keys" in agents_config and provider in agents_config["api_keys"]:
                return agents_config["api_keys"][provider]
        
        # ê¸°ë³¸ í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸° (í•„ìš”í•œ ê²½ìš°)
        return ""
    
    def get_available_ollama_models(self, api_base: str = "http://localhost:11434/api") -> List[str]:
        """
        Ollamaì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            api_base (str): Ollama API ê¸°ë³¸ URL
            
        Returns:
            List[str]: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡
        """
        # ìºì‹œëœ ëª¨ë¸ ëª©ë¡ì´ ìˆìœ¼ë©´ ë°˜í™˜
        if self.available_models_cache is not None:
            return self.available_models_cache
        
        try:
            url = f"{api_base.rstrip('/')}/tags"
            response = requests.get(url, timeout=3)
            response.raise_for_status()
            models = response.json().get("models", [])
            model_names = [model.get("name") for model in models]
            
            # ëª¨ë¸ ëª©ë¡ ìºì‹œ
            self.available_models_cache = model_names
            return model_names
        except Exception as e:
            print(f"âš ï¸ Ollama ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return []
    
    def get_alternative_model(self, requested_model: str, api_base: str = "http://localhost:11434/api") -> str:
        """
        ìš”ì²­ëœ ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš° ëŒ€ì²´ ëª¨ë¸ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Args:
            requested_model (str): ìš”ì²­ëœ ëª¨ë¸ëª…
            api_base (str): Ollama API ê¸°ë³¸ URL
            
        Returns:
            str: ëŒ€ì²´ ëª¨ë¸ëª… (ì‚¬ìš© ê°€ëŠ¥í•œ ëŒ€ì²´ ëª¨ë¸ì´ ì—†ìœ¼ë©´ ì›ë˜ ëª¨ë¸ëª… ë°˜í™˜)
        """
        available_models = self.get_available_ollama_models(api_base)
        
        # ìš”ì²­ëœ ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if requested_model in available_models:
            return requested_model
        
        # ëª¨ë¸ì´ ì—†ìœ¼ë©´ ëŒ€ì²´ ëª¨ë¸ ì°¾ê¸°
        print(f"âš ï¸ ëª¨ë¸ '{requested_model}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # llama3 ê´€ë ¨ ëª¨ë¸ ë¨¼ì € í™•ì¸
        if "llama3" in requested_model.lower():
            llama3_models = [m for m in available_models if "llama3" in m.lower()]
            if llama3_models:
                alternative = llama3_models[0]
                print(f"ğŸ’¡ ëŒ€ì²´ ëª¨ë¸ë¡œ '{alternative}'ì„(ë¥¼) ì‚¬ìš©í•©ë‹ˆë‹¤.")
                return alternative
        
        # ë‹¤ë¥¸ llama ëª¨ë¸ í™•ì¸
        llama_models = [m for m in available_models if "llama" in m.lower()]
        if llama_models:
            alternative = llama_models[0]
            print(f"ğŸ’¡ ëŒ€ì²´ ëª¨ë¸ë¡œ '{alternative}'ì„(ë¥¼) ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return alternative
            
        # codellama ëª¨ë¸ í™•ì¸
        codellama_models = [m for m in available_models if "codellama" in m.lower()]
        if codellama_models:
            alternative = codellama_models[0]
            print(f"ğŸ’¡ ëŒ€ì²´ ëª¨ë¸ë¡œ '{alternative}'ì„(ë¥¼) ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return alternative
        
        # ê·¸ ì™¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ëª¨ë¸ ì‚¬ìš©
        if available_models:
            alternative = available_models[0]
            print(f"ğŸ’¡ ëŒ€ì²´ ëª¨ë¸ë¡œ '{alternative}'ì„(ë¥¼) ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return alternative
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìœ¼ë©´ ì›ë˜ ëª¨ë¸ ë°˜í™˜
        print("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëŒ€ì²´ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ì›ë˜ ëª¨ë¸ëª…ì„ ìœ ì§€í•©ë‹ˆë‹¤.")
        return requested_model
    
    def create_agent(self, agent_type: str, **kwargs) -> Any:
        """
        ì—ì´ì „íŠ¸ ìƒì„±
        
        Args:
            agent_type (str): ì—ì´ì „íŠ¸ ìœ í˜• (pm, designer, frontend, backend, ai_engineer)
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜
                - api_key: API í‚¤
                - ollama_model: Ollama ëª¨ë¸ëª… (ê¸°ë³¸ê°’: "llama3:latest")
                - ollama_api_base: Ollama API ê¸°ë³¸ URL (ê¸°ë³¸ê°’: "http://localhost:11434/api")
                - use_mcp: MCP ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
                - temperature: ìƒì„± ì˜¨ë„ (ê¸°ë³¸ê°’: 0.7)
                - auto_register: PM ì—ì´ì „íŠ¸ì— ë‹¤ë¥¸ ì—ì´ì „íŠ¸ ìë™ ë“±ë¡ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
            
        Returns:
            Any: ìƒì„±ëœ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤
            
        Raises:
            ValueError: ìœ íš¨í•˜ì§€ ì•Šì€ ì—ì´ì „íŠ¸ ìœ í˜•
        """
        # API í‚¤ ì„¤ì •
        api_key = kwargs.get("api_key", self.get_api_key(agent_type))
        
        # Ollama ê´€ë ¨ ì„¤ì •
        ollama_model = kwargs.get("ollama_model", "llama3:latest")
        ollama_api_base = kwargs.get("ollama_api_base", "http://localhost:11434/api")
        
        # ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ ë° ëŒ€ì²´ ëª¨ë¸ ì„ íƒ
        actual_model = self.get_alternative_model(ollama_model, ollama_api_base)
        
        # ìºì‹œì—ì„œ ì—ì´ì „íŠ¸ í™•ì¸
        cache_key = f"{agent_type}_{actual_model}"
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        # MCP ê´€ë ¨ ì„¤ì •
        use_mcp = kwargs.get("use_mcp", False)
        mcp_helper = None
        if use_mcp and MCP_AVAILABLE:
            mcp_helper = self.create_mcp_helper(**kwargs)
        
        # ìƒì„± ì˜¨ë„
        temperature = kwargs.get("temperature", 0.7)
        
        # ìë™ ë“±ë¡ ì—¬ë¶€
        auto_register = kwargs.get("auto_register", False)
        
        # ì—ì´ì „íŠ¸ ìœ í˜•ì— ë”°ë¼ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        if agent_type == "pm":
            agent = PMAgentOllama(
                api_key=api_key,
                api_base=ollama_api_base,
                model=actual_model,
                use_mcp=use_mcp,
                mcp_helper=mcp_helper,
                temperature=temperature
            )
            
            # ìë™ ë“±ë¡ì´ í™œì„±í™”ëœ ê²½ìš° ë‹¤ë¥¸ ì—ì´ì „íŠ¸ ë“±ë¡
            if auto_register:
                # ollama_model ì œê±°í•˜ì—¬ ì¤‘ë³µ ì „ë‹¬ ë°©ì§€
                register_kwargs = kwargs.copy()
                if "ollama_model" in register_kwargs:
                    del register_kwargs["ollama_model"]
                
                self._register_agents_to_pm(
                    agent, 
                    actual_model, 
                    ollama_api_base, 
                    use_mcp, 
                    mcp_helper, 
                    temperature, 
                    **register_kwargs
                )
                
        elif agent_type == "designer":
            agent = DesignerAgentOllama(
                api_key=api_key,
                api_base=ollama_api_base,
                model=actual_model,
                use_mcp=use_mcp,
                mcp_helper=mcp_helper,
                temperature=temperature
            )
        elif agent_type == "frontend":
            agent = FrontendAgentOllama(
                api_key=api_key,
                api_base=ollama_api_base,
                model=actual_model,
                use_mcp=use_mcp,
                mcp_helper=mcp_helper,
                temperature=temperature
            )
        elif agent_type == "backend":
            agent = BackendAgentOllama(
                api_key=api_key,
                api_base=ollama_api_base,
                model=actual_model,
                use_mcp=use_mcp,
                mcp_helper=mcp_helper,
                temperature=temperature
            )
        elif agent_type == "ai_engineer":
            agent = AIEngineerAgentOllama(
                api_key=api_key,
                api_base=ollama_api_base,
                model=actual_model,
                use_mcp=use_mcp,
                mcp_helper=mcp_helper,
                temperature=temperature
            )
        else:
            raise ValueError(f"ìœ íš¨í•˜ì§€ ì•Šì€ ì—ì´ì „íŠ¸ ìœ í˜•: {agent_type}")
        
        # ì—ì´ì „íŠ¸ ìºì‹±
        self.cache[cache_key] = agent
        
        return agent
    
    def _register_agents_to_pm(self, pm_agent: PMAgentOllama, 
                              ollama_model: str, ollama_api_base: str, 
                              use_mcp: bool, mcp_helper: Any, 
                              temperature: float, **kwargs) -> None:
        """
        PM ì—ì´ì „íŠ¸ì— ë‹¤ë¥¸ ì—ì´ì „íŠ¸ë“¤ì„ ë“±ë¡í•©ë‹ˆë‹¤.
        
        Args:
            pm_agent: PM ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤
            ollama_model: Ollama ëª¨ë¸ëª…
            ollama_api_base: Ollama API ê¸°ë³¸ URL
            use_mcp: MCP ì‚¬ìš© ì—¬ë¶€
            mcp_helper: MCP í—¬í¼ ì¸ìŠ¤í„´ìŠ¤
            temperature: ìƒì„± ì˜¨ë„
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜
        """
        # ì—ì´ì „íŠ¸ ìœ í˜• ëª©ë¡ (PM ì œì™¸)
        agent_types = ["designer", "frontend", "backend", "ai_engineer"]
        
        # ê° ì—ì´ì „íŠ¸ ìœ í˜•ì— ëŒ€í•´ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ë“±ë¡
        for agent_type in agent_types:
            # ì—ì´ì „íŠ¸ ìœ í˜•ë³„ ëª¨ë¸ ì˜¤ë²„ë¼ì´ë“œ í™•ì¸
            model_key = f"{agent_type}_model"
            agent_model = kwargs.get(model_key, ollama_model)
            
            # ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ ë° ëŒ€ì²´ ëª¨ë¸ ì„ íƒ
            actual_model = self.get_alternative_model(agent_model, ollama_api_base)
            
            # ìºì‹œ í™•ì¸ ë˜ëŠ” ìƒˆë¡œ ìƒì„±
            cache_key = f"{agent_type}_{actual_model}"
            if cache_key in self.cache:
                agent = self.cache[cache_key]
            else:
                # ì—ì´ì „íŠ¸ ìƒì„±
                api_key = kwargs.get("api_key", self.get_api_key(agent_type))
                
                if agent_type == "designer":
                    agent = DesignerAgentOllama(
                        api_key=api_key,
                        api_base=ollama_api_base,
                        model=actual_model,
                        use_mcp=use_mcp,
                        mcp_helper=mcp_helper,
                        temperature=temperature
                    )
                elif agent_type == "frontend":
                    agent = FrontendAgentOllama(
                        api_key=api_key,
                        api_base=ollama_api_base,
                        model=actual_model,
                        use_mcp=use_mcp,
                        mcp_helper=mcp_helper,
                        temperature=temperature
                    )
                elif agent_type == "backend":
                    agent = BackendAgentOllama(
                        api_key=api_key,
                        api_base=ollama_api_base,
                        model=actual_model,
                        use_mcp=use_mcp,
                        mcp_helper=mcp_helper,
                        temperature=temperature
                    )
                elif agent_type == "ai_engineer":
                    agent = AIEngineerAgentOllama(
                        api_key=api_key,
                        api_base=ollama_api_base,
                        model=actual_model,
                        use_mcp=use_mcp,
                        mcp_helper=mcp_helper,
                        temperature=temperature
                    )
                    
                # ì—ì´ì „íŠ¸ ìºì‹±
                self.cache[cache_key] = agent
            
            # PM ì—ì´ì „íŠ¸ì— ë“±ë¡
            pm_agent.register_agent(agent_type, agent)
    
    def create_mcp_helper(self, **kwargs) -> MCPAgentHelper:
        """
        MCP í—¬í¼ ìƒì„±
        
        Args:
            **kwargs: MCPAgentHelper ìƒì„±ì— í•„ìš”í•œ ì¶”ê°€ ë§¤ê°œë³€ìˆ˜
            
        Returns:
            MCPAgentHelper: ìƒì„±ëœ MCP í—¬í¼ ì¸ìŠ¤í„´ìŠ¤
        """
        # ìºì‹œì—ì„œ MCP í—¬í¼ í™•ì¸
        if "mcp_helper" in self.cache:
            return self.cache["mcp_helper"]
        
        # ì„¤ì •ì—ì„œ ë§¤ê°œë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
        unity_mcp_host = kwargs.get("unity_mcp_host", os.environ.get("UNITY_MCP_HOST"))
        github_token = kwargs.get("github_token", os.environ.get("GITHUB_TOKEN"))
        figma_token = kwargs.get("figma_token", os.environ.get("FIGMA_TOKEN"))
        db_connection_string = kwargs.get("db_connection_string", os.environ.get("DB_CONNECTION_STRING"))
        
        # MCP í—¬í¼ ìƒì„±
        helper = MCPAgentHelper(
            unity_mcp_host=unity_mcp_host,
            github_token=github_token,
            figma_token=figma_token,
            db_connection_string=db_connection_string
        )
        
        # MCP í—¬í¼ ìºì‹±
        self.cache["mcp_helper"] = helper
        
        return helper
    
    def clear_cache(self):
        """
        ì—ì´ì „íŠ¸ ìºì‹œ ì´ˆê¸°í™”
        """
        self.cache = {}
    
    def create_all_agents(self, connect_to_pm: bool = True, **kwargs) -> Dict[str, Any]:
        """
        ëª¨ë“  ìœ í˜•ì˜ ì—ì´ì „íŠ¸ ìƒì„±
        
        Args:
            connect_to_pm: ìƒì„±ëœ ì—ì´ì „íŠ¸ë“¤ì„ PM ì—ì´ì „íŠ¸ì— ì—°ê²°í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜ (ollama_model, ollama_api_base ë“±)
                - ollama_model: ê¸°ë³¸ Ollama ëª¨ë¸ (ê¸°ë³¸ê°’: "llama3:latest")
                - ollama_api_base: Ollama API ê¸°ë³¸ URL
                - use_mcp: MCP ì‚¬ìš© ì—¬ë¶€
                - ê° ì—ì´ì „íŠ¸ë³„ ëª¨ë¸ ì§€ì •: designer_model, frontend_model, backend_model, ai_engineer_model
            
        Returns:
            Dict[str, Any]: ì—ì´ì „íŠ¸ ìœ í˜•ì„ í‚¤ë¡œ, ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°’ìœ¼ë¡œ í•˜ëŠ” ì‚¬ì „
        """
        agents = {}
        agent_types = ["designer", "frontend", "backend", "ai_engineer"]
        
        # Ollama API ê¸°ë³¸ URL
        ollama_api_base = kwargs.get("ollama_api_base", "http://localhost:11434/api")
        
        # ê¸°ë³¸ ëª¨ë¸ ë° ëª¨ë¸ ê°€ìš©ì„± í™•ì¸
        base_model = kwargs.get("ollama_model", "llama3:latest")
        actual_base_model = self.get_alternative_model(base_model, ollama_api_base)
        
        # PM ì—ì´ì „íŠ¸ëŠ” connect_to_pmì´ Trueì¼ ë•ŒëŠ” ë§ˆì§€ë§‰ì— ìƒì„±
        if not connect_to_pm:
            agent_types.insert(0, "pm")
        
        # ë‹¤ë¥¸ ì—ì´ì „íŠ¸ë“¤ ë¨¼ì € ìƒì„±
        for agent_type in agent_types:
            # ì—ì´ì „íŠ¸ë³„ ëª¨ë¸ ì˜¤ë²„ë¼ì´ë“œ í™•ì¸
            model_key = f"{agent_type}_model"
            agent_model = kwargs.get(model_key, actual_base_model)
            
            # ì—ì´ì „íŠ¸ ìƒì„± (ì´ë¯¸ get_alternative_modelì´ create_agent ë‚´ë¶€ì—ì„œ í˜¸ì¶œë¨)
            # kwargsì—ì„œ ollama_modelì„ ì œê±°í•˜ê³  ë³„ë„ë¡œ ì „ë‹¬
            agent_kwargs = kwargs.copy()
            if "ollama_model" in agent_kwargs:
                del agent_kwargs["ollama_model"]
            
            agents[agent_type] = self.create_agent(
                agent_type,
                ollama_model=agent_model,
                **agent_kwargs
            )
        
        # PM ì—ì´ì „íŠ¸ê°€ ë§ˆì§€ë§‰ì— ìƒì„±ë˜ì–´ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ë“¤ì„ ìë™ ë“±ë¡
        if connect_to_pm:
            # PM ì—ì´ì „íŠ¸ë³„ ëª¨ë¸ ì˜¤ë²„ë¼ì´ë“œ í™•ì¸
            pm_model = kwargs.get("pm_model", actual_base_model)
            
            # kwargsì—ì„œ ollama_modelì„ ì œê±°í•˜ê³  ë³„ë„ë¡œ ì „ë‹¬
            pm_kwargs = kwargs.copy()
            if "ollama_model" in pm_kwargs:
                del pm_kwargs["ollama_model"]
            
            agents["pm"] = self.create_agent(
                "pm",
                ollama_model=pm_model,
                auto_register=True,
                **pm_kwargs
            )
            
            # ë“±ë¡ ê²°ê³¼ í™•ì¸
            if hasattr(agents["pm"], "agents"):
                all_registered = True
                for agent_type in agent_types:
                    if not agents["pm"].agents.get(agent_type):
                        all_registered = False
                        break
                
                if not all_registered:
                    # ìˆ˜ë™ìœ¼ë¡œ ì—ì´ì „íŠ¸ ë“±ë¡
                    for agent_type in agent_types:
                        if agent_type in agents and agent_type in agents["pm"].agents:
                            agents["pm"].register_agent(agent_type, agents[agent_type])
        
        return agents


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    factory = AgentFactory()
    
    try:
        # ìë™ ë“±ë¡ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ PM ì—ì´ì „íŠ¸ ìƒì„±
        pm_agent = factory.create_agent("pm", auto_register=True)
        print(f"PM ì—ì´ì „íŠ¸ ìƒì„± ì„±ê³µ: {type(pm_agent).__name__}")
        
        # ë“±ë¡ëœ ì—ì´ì „íŠ¸ í™•ì¸
        registered_agents = {agent_type: agent is not None for agent_type, agent in pm_agent.agents.items()}
        print(f"ë“±ë¡ëœ ì—ì´ì „íŠ¸ í˜„í™©: {registered_agents}")
        
        # create_all_agents ë©”ì„œë“œ í…ŒìŠ¤íŠ¸
        print("\nëª¨ë“  ì—ì´ì „íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸")
        all_agents = factory.create_all_agents(connect_to_pm=True)
        print(f"ìƒì„±ëœ ì—ì´ì „íŠ¸ ìˆ˜: {len(all_agents)}")
        
        # PM ì—ì´ì „íŠ¸ì— ë“±ë¡ëœ ì—ì´ì „íŠ¸ í™•ì¸
        pm = all_agents["pm"]
        registered_count = sum(1 for agent in pm.agents.values() if agent is not None)
        print(f"PM ì—ì´ì „íŠ¸ì— ë“±ë¡ëœ ì—ì´ì „íŠ¸ ìˆ˜: {registered_count}")
        
    except Exception as e:
        print(f"ì—ì´ì „íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}") 