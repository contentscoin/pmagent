"""
Ollama APIë¥¼ í™œìš©í•œ ë””ìì´ë„ˆ ì—ì´ì „íŠ¸ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ Ollamaë¥¼ í†µí•´ ë¡œì»¬ì—ì„œ ì‹¤í–‰ë˜ëŠ” LLMì„ ì‚¬ìš©í•˜ì—¬ ë””ìì¸ ê´€ë ¨ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
PM ì—ì´ì „íŠ¸ì˜ ì§€ì‹œì— ë”°ë¼ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
"""

import os
import json
import time
import requests
import logging
from typing import Dict, List, Optional, Any, Union

# MCP Agent Helper ê°€ì ¸ì˜¤ê¸° (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
try:
    from .mcp_agent_helper import MCPAgentHelper
    MCP_AVAILABLE = True
except ImportError:
    MCP_AVAILABLE = False

from .base_tool import BaseTool

logger = logging.getLogger(__name__)

class DesignerAgentOllama(BaseTool):
    """
    Ollama APIë¥¼ ì‚¬ìš©í•˜ëŠ” Designer Agent
    
    ë””ìì¸ ê´€ë ¨ ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” Ollama ê¸°ë°˜ ì—ì´ì „íŠ¸
    - UI/UX ë””ìì¸
    - ì™€ì´ì–´í”„ë ˆì„ ì‘ì„±
    - ë””ìì¸ ì‹œìŠ¤í…œ ê´€ë¦¬
    - ì»´í¬ë„ŒíŠ¸ ë””ìì¸
    - ë””ìì¸ ê°€ì´ë“œë¼ì¸ ì œê³µ
    """
    
    name = "designer_agent_ollama"
    description = "Ollama ê¸°ë°˜ Designer Agent - UI/UX ë””ìì¸ ê´€ë ¨ ì‘ì—… ì²˜ë¦¬"
    
    def __init__(self, api_key=None, model="llama3.2:latest", api_base="http://localhost:11434", **kwargs):
        """
        ë””ìì´ë„ˆ ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        
        Args:
            api_key (str, optional): API í‚¤
            model (str, optional): Ollama ëª¨ë¸ëª…. ê¸°ë³¸ê°’ì€ "llama3.2:latest"
            api_base (str, optional): Ollama API ê¸°ë³¸ URL. ê¸°ë³¸ê°’ì€ "http://localhost:11434"
        """
        self.api_key = api_key
        self.model = model
        self.api_base = api_base
        
        # API URLì´ /apië¡œ ëë‚˜ì§€ ì•Šìœ¼ë©´ ì¶”ê°€
        if not self.api_base.endswith('/api'):
            self.api_base = f"{self.api_base}/api"
        
        # ë””ìì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.design_system = {
            "ìƒ‰ìƒ": {
                "primary": {
                    "main": "#3A86FF",
                    "light": "#7CB0FF",
                    "dark": "#0063CC"
                },
                "secondary": {
                    "main": "#8338EC",
                    "light": "#B26EFF",
                    "dark": "#5900B9"
                },
                "accent": {
                    "main": "#FF006E",
                    "light": "#FF5998",
                    "dark": "#C50046"
                },
                "ë°°ê²½": {
                    "light": "#FFFFFF",
                    "dark": "#121212",
                    "muted": "#F5F5F5"
                },
                "í…ìŠ¤íŠ¸": {
                    "primary": "#212121",
                    "secondary": "#757575",
                    "disabled": "#BDBDBD"
                }
            },
            "íƒ€ì´í¬ê·¸ë˜í”¼": {
                "í°íŠ¸íŒ¨ë°€ë¦¬": {
                    "ê¸°ë³¸": "Pretendard, sans-serif",
                    "ì œëª©": "Pretendard, sans-serif",
                    "ì½”ë“œ": "JetBrains Mono, monospace"
                },
                "í¬ê¸°": {
                    "h1": "2.5rem",
                    "h2": "2rem",
                    "h3": "1.75rem",
                    "h4": "1.5rem",
                    "h5": "1.25rem",
                    "h6": "1rem",
                    "ë³¸ë¬¸": "1rem",
                    "ì‘ê²Œ": "0.875rem",
                    "ë§¤ìš°ì‘ê²Œ": "0.75rem"
                },
                "ë‘ê»˜": {
                    "ê°€ëŠ˜ê²Œ": 300,
                    "ì¼ë°˜": 400,
                    "ì¤‘ê°„": 500,
                    "êµµê²Œ": 700,
                    "ë§¤ìš°êµµê²Œ": 900
                }
            },
            "ê°„ê²©": {
                "xs": "0.25rem",
                "sm": "0.5rem",
                "md": "1rem",
                "lg": "1.5rem",
                "xl": "2rem",
                "xxl": "3rem"
            },
            "ê·¸ë¦¼ì": {
                "ì‘ê²Œ": "0 2px 4px rgba(0,0,0,0.1)",
                "ì¤‘ê°„": "0 4px 8px rgba(0,0,0,0.1)",
                "í¬ê²Œ": "0 8px 16px rgba(0,0,0,0.1)"
            },
            "ë°˜ê²½": {
                "ì‘ê²Œ": "4px",
                "ì¤‘ê°„": "8px",
                "í¬ê²Œ": "16px",
                "ì›í˜•": "50%"
            }
        }
        
        # Ollama ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ í™•ì¸
        self._check_model_availability()
        
        logger.info(f"ë””ìì´ë„ˆ ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ëª¨ë¸: {self.model}")
        
        # ì‘ì—… ê¸°ë¡
        self.task_history = []
    
    def _check_model_availability(self):
        """
        ì„ íƒí•œ Ollama ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸í•©ë‹ˆë‹¤.
        
        Returns:
            bool: ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ True, ì•„ë‹ˆë©´ False
        """
        models = self.get_available_models()
        
        if not models:
            print("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
            return False
            
        if self.model in models:
            print(f"âœ… ëª¨ë¸ '{self.model}'ì´(ê°€) ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            return True
        else:
            print(f"âš ï¸ ëª¨ë¸ '{self.model}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # llama3.2 ë˜ëŠ” llama3 ê´€ë ¨ ëª¨ë¸ì´ ìˆëŠ”ì§€ í™•ì¸
            llama3_models = [m for m in models if "llama3" in m.lower()]
            if llama3_models:
                recommended = llama3_models[0]
                print(f"ğŸ’¡ ëŒ€ì²´ ëª¨ë¸ë¡œ '{recommended}'ì„(ë¥¼) ì‚¬ìš©í•´ ë³´ì„¸ìš”.")
                print(f"   ëª…ë ¹ì–´: ollama pull {recommended}")
            else:
                print("ğŸ’¡ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ í•„ìš”í•œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”:")
                print("   ollama pull llama3.2:latest")
                
            return False
    
    def get_available_models(self):
        """
        Ollama APIì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Returns:
            list: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì´ë¦„ ëª©ë¡
        """
        try:
            url = f"{self.api_base}/tags"
            response = requests.get(url)
            
            if response.status_code == 200:
                data = response.json()
                # ëª¨ë¸ ì´ë¦„ ì¶”ì¶œ
                models = [model['name'] for model in data.get('models', [])]
                return models
            else:
                print(f"âš ï¸ ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: HTTP {response.status_code}")
                return []
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return []
    
    def _call_ollama_api(self, prompt: str, system_prompt: Optional[str] = None, 
                         temperature: float = 0.7, max_tokens: int = 800) -> str:
        """
        Ollama API í˜¸ì¶œ
        
        Args:
            prompt: í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì§€ì‹œì‚¬í•­)
            temperature: ì˜¨ë„ (ì°½ì˜ì„± ì¡°ì ˆ)
            max_tokens: ìµœëŒ€ í† í° ìˆ˜
            
        Returns:
            str: API ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        url = f"{self.api_base}/generate"
        
        payload = {
            "model": self.model,
            "prompt": prompt,
            "temperature": temperature,
            "num_predict": max_tokens,
            "options": {}
        }
        
        if system_prompt:
            payload["system"] = system_prompt
        
        try:
            response = requests.post(url, json=payload)
            response.raise_for_status()
            return response.json().get("response", "ì‘ë‹µì„ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            return f"Ollama API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def _run(self, task: Dict[str, Any]) -> str:
        """
        Designer Agentë¡œ ì‘ì—…ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Args:
            task: ì‘ì—… ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” ì‘ì—… ì„¤ëª… ë¬¸ìì—´
            
        Returns:
            str: ì‘ì—… ê²°ê³¼
        """
        # taskê°€ ë¬¸ìì—´ì¸ ê²½ìš° ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        if isinstance(task, str):
            task = {"task": task}
        
        task_desc = task.get("task", "")
        task_type = self._determine_task_type(task_desc)
        
        # MCP ë°ì´í„° ì¶”ê°€ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        if self.use_mcp and self.mcp_helper:
            if task_type == "ui_component" and hasattr(self.mcp_helper, "get_design_data"):
                try:
                    # Figmaì—ì„œ ë””ìì¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    figma_data = self.mcp_helper.get_design_data("component", task_desc)
                    if figma_data:
                        task["figma_data"] = figma_data
                except Exception as e:
                    logger.error(f"Figma ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
        
        # ì‘ì—… ìœ í˜•ì— ë”°ë¼ ë‹¤ë¥¸ ì²˜ë¦¬
        if task_type == "design_system":
            result = self._handle_design_system_task(task_desc)
        elif task_type == "wireframe":
            result = self._handle_wireframe_task(task_desc, task.get("figma_data"))
        elif task_type == "ui_component":
            result = self._handle_ui_component_task(task_desc, task.get("figma_data"))
        elif task_type == "design_review":
            result = self._handle_design_review_task(task_desc)
        else:
            # ê¸°ë³¸ ì‘ì—… ì²˜ë¦¬
            result = self._handle_general_design_task(task_desc)
        
        # ì‘ì—… ê¸°ë¡ì— ì¶”ê°€
        self.task_history.append({
            "timestamp": time.time(),
            "task": task_desc,
            "type": task_type,
            "result_length": len(result)
        })
        
        return result
    
    def _determine_task_type(self, task_desc: str) -> str:
        """
        ì‘ì—… ì„¤ëª…ì—ì„œ ì‘ì—… ìœ í˜•ì„ íŒë‹¨í•©ë‹ˆë‹¤.
        
        Args:
            task_desc: ì‘ì—… ì„¤ëª…
            
        Returns:
            str: ì‘ì—… ìœ í˜• (design_system, wireframe, ui_component, design_review, general)
        """
        task_desc_lower = task_desc.lower()
        
        if "ë””ìì¸ ì‹œìŠ¤í…œ" in task_desc_lower or "design system" in task_desc_lower or "ìƒ‰ìƒ" in task_desc_lower or "íƒ€ì´í¬ê·¸ë˜í”¼" in task_desc_lower:
            return "design_system"
        elif "ì™€ì´ì–´í”„ë ˆì„" in task_desc_lower or "wireframe" in task_desc_lower or "ë ˆì´ì•„ì›ƒ" in task_desc_lower:
            return "wireframe"
        elif "ì»´í¬ë„ŒíŠ¸" in task_desc_lower or "component" in task_desc_lower or "ui ìš”ì†Œ" in task_desc_lower or "ë²„íŠ¼" in task_desc_lower or "í¼" in task_desc_lower:
            return "ui_component"
        elif "ë¦¬ë·°" in task_desc_lower or "review" in task_desc_lower or "ê°œì„ " in task_desc_lower or "í”¼ë“œë°±" in task_desc_lower:
            return "design_review"
        else:
            return "general"
    
    def _handle_design_system_task(self, task_desc: str) -> str:
        """
        ë””ìì¸ ì‹œìŠ¤í…œ ê´€ë ¨ ì‘ì—… ì²˜ë¦¬
        
        Args:
            task_desc: ì‘ì—… ì„¤ëª…
            
        Returns:
            str: ì‘ì—… ê²°ê³¼
        """
        system_prompt = """
        ë‹¹ì‹ ì€ UI/UX ë””ìì´ë„ˆë¡œ ë””ìì¸ ì‹œìŠ¤í…œì„ ë§Œë“¤ê³  ê´€ë¦¬í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
        ë””ìì¸ ì‹œìŠ¤í…œì—ëŠ” ë‹¤ìŒ ìš”ì†Œê°€ í¬í•¨ë©ë‹ˆë‹¤:
        - ìƒ‰ìƒ íŒ”ë ˆíŠ¸ (ë¸Œëœë“œ, ê¸°ëŠ¥ë³„, ì˜ë¯¸ë³„)
        - íƒ€ì´í¬ê·¸ë˜í”¼ (ì„œì²´, í¬ê¸°, ìŠ¤íƒ€ì¼)
        - ê°„ê²© ì‹œìŠ¤í…œ (ë§ˆì§„, íŒ¨ë”©)
        - ì»´í¬ë„ŒíŠ¸ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ
        
        ì‚¬ìš©ìì˜ ìš”êµ¬ì— ë§ê²Œ ëª…í™•í•˜ê³  ì¼ê´€ëœ ë””ìì¸ ì‹œìŠ¤í…œì„ ì œì•ˆí•˜ì„¸ìš”.
        """
        
        # í˜„ì¬ ë””ìì¸ ì‹œìŠ¤í…œ ì •ë³´ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
        í˜„ì¬ ë””ìì¸ ì‹œìŠ¤í…œ:
        {json.dumps(self.design_system, indent=2, ensure_ascii=False)}
        
        ì‘ì—… ìš”ì²­: {task_desc}
        
        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ ë””ìì¸ ì‹œìŠ¤í…œ ìš”ì†Œë¥¼ ìƒì„±í•˜ê±°ë‚˜ ìˆ˜ì •í•´ì£¼ì„¸ìš”.
        ê²°ê³¼ëŠ” Markdown í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
        """
        
        result = self._call_ollama_api(prompt, system_prompt, temperature=0.7, max_tokens=1500)
        
        # ë””ìì¸ ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ ì—¬ë¶€ í™•ì¸ ë° ì²˜ë¦¬
        if "```json" in result:
            try:
                json_start = result.find("```json") + 7
                json_end = result.find("```", json_start)
                json_content = result[json_start:json_end].strip()
                
                updated_design_system = json.loads(json_content)
                # ë¶€ë¶„ ì—…ë°ì´íŠ¸ ì²˜ë¦¬
                if isinstance(updated_design_system, dict):
                    for key, value in updated_design_system.items():
                        if key in self.design_system and isinstance(value, dict):
                            self.design_system[key].update(value)
                        else:
                            self.design_system[key] = value
            except Exception as e:
                logger.error(f"ë””ìì¸ ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        return result
    
    def _handle_wireframe_task(self, task_desc: str, figma_data: Optional[Dict[str, Any]] = None) -> str:
        """
        ì™€ì´ì–´í”„ë ˆì„ ê´€ë ¨ ì‘ì—… ì²˜ë¦¬
        
        Args:
            task_desc: ì‘ì—… ì„¤ëª…
            figma_data: Figmaì—ì„œ ê°€ì ¸ì˜¨ ë””ìì¸ ë°ì´í„° (ì˜µì…˜)
            
        Returns:
            str: ì‘ì—… ê²°ê³¼
        """
        system_prompt = """
        ë‹¹ì‹ ì€ UI/UX ë””ìì´ë„ˆë¡œ ì™€ì´ì–´í”„ë ˆì„ì„ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì™€ì´ì–´í”„ë ˆì„ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”:
        
        1. ë ˆì´ì•„ì›ƒ êµ¬ì¡° ì„¤ëª…
        2. ì£¼ìš” ì˜ì—­ ë° ìš”ì†Œ ë‚˜ì—´
        3. ì¸í„°ë™ì…˜ ë° íë¦„ ì„¤ëª…
        4. ë°˜ì‘í˜• ë””ìì¸ ê³ ë ¤ì‚¬í•­
        
        ìƒì„¸í•˜ê³  êµ¬ì²´ì ì¸ ì™€ì´ì–´í”„ë ˆì„ ì„¤ê³„ë¥¼ ì œê³µí•˜ì„¸ìš”.
        """
        
        # Figma ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        figma_prompt = ""
        if figma_data:
            figma_prompt = f"""
            ì°¸ê³ í•  Figma ë””ìì¸ ë°ì´í„°:
            {json.dumps(figma_data, indent=2, ensure_ascii=False)}
            """
        
        prompt = f"""
        í˜„ì¬ ë””ìì¸ ì‹œìŠ¤í…œ:
        {json.dumps(self.design_system, indent=2, ensure_ascii=False)}
        
        {figma_prompt}
        
        ì‘ì—… ìš”ì²­: {task_desc}
        
        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ì™€ì´ì–´í”„ë ˆì„ ì„¤ëª…ì„ ì œê³µí•´ì£¼ì„¸ìš”.
        ê²°ê³¼ëŠ” Markdown í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì‹œê³ , ê°€ëŠ¥í•˜ë©´ ASCII ì•„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë ˆì´ì•„ì›ƒì„ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”.
        """
        
        return self._call_ollama_api(prompt, system_prompt, temperature=0.7, max_tokens=2000)
    
    def _handle_ui_component_task(self, task_desc: str, figma_data: Optional[Dict[str, Any]] = None) -> str:
        """
        UI ì»´í¬ë„ŒíŠ¸ ê´€ë ¨ ì‘ì—… ì²˜ë¦¬
        
        Args:
            task_desc: ì‘ì—… ì„¤ëª…
            figma_data: Figmaì—ì„œ ê°€ì ¸ì˜¨ ë””ìì¸ ë°ì´í„° (ì˜µì…˜)
            
        Returns:
            str: ì‘ì—… ê²°ê³¼
        """
        system_prompt = """
        ë‹¹ì‹ ì€ UI/UX ë””ìì´ë„ˆë¡œ UI ì»´í¬ë„ŒíŠ¸ë¥¼ ë””ìì¸í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ UI ì»´í¬ë„ŒíŠ¸ ë””ìì¸ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”:
        
        1. ì»´í¬ë„ŒíŠ¸ ê¸°ë³¸ ì„¤ëª… ë° ì‚¬ìš© ëª©ì 
        2. ì‹œê°ì  ë””ìì¸ ìš”ì†Œ (ìƒ‰ìƒ, í˜•íƒœ, íƒ€ì´í¬ê·¸ë˜í”¼)
        3. ìƒíƒœ ë³€í™” (ê¸°ë³¸, í˜¸ë²„, í™œì„±, ë¹„í™œì„±)
        4. ì ‘ê·¼ì„± ê³ ë ¤ì‚¬í•­
        5. ë³€í˜• ë° ì‚¬ì´ì¦ˆ ì˜µì…˜
        
        ê°€ëŠ¥í•˜ë©´ HTML/CSS ì½”ë“œ ì˜ˆì‹œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.
        """
        
        # Figma ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        figma_prompt = ""
        if figma_data:
            figma_prompt = f"""
            ì°¸ê³ í•  Figma ë””ìì¸ ë°ì´í„°:
            {json.dumps(figma_data, indent=2, ensure_ascii=False)}
            """
        
        prompt = f"""
        í˜„ì¬ ë””ìì¸ ì‹œìŠ¤í…œ:
        {json.dumps(self.design_system, indent=2, ensure_ascii=False)}
        
        {figma_prompt}
        
        ì‘ì—… ìš”ì²­: {task_desc}
        
        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ UI ì»´í¬ë„ŒíŠ¸ ë””ìì¸ì„ ì œê³µí•´ì£¼ì„¸ìš”.
        ê²°ê³¼ëŠ” Markdown í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì‹œê³ , HTML/CSS ì½”ë“œ ì˜ˆì‹œë¥¼ í•¨ê»˜ ì œê³µí•´ì£¼ì„¸ìš”.
        """
        
        return self._call_ollama_api(prompt, system_prompt, temperature=0.7, max_tokens=2000)
    
    def _handle_design_review_task(self, task_desc: str) -> str:
        """
        ë””ìì¸ ë¦¬ë·° ê´€ë ¨ ì‘ì—… ì²˜ë¦¬
        
        Args:
            task_desc: ì‘ì—… ì„¤ëª…
            
        Returns:
            str: ì‘ì—… ê²°ê³¼
        """
        system_prompt = """
        ë‹¹ì‹ ì€ UI/UX ë””ìì¸ ë¦¬ë·°ì–´ì…ë‹ˆë‹¤. ë‹¤ìŒ í•­ëª©ì„ í¬í•¨í•œ ì¢…í•©ì ì¸ ë””ìì¸ ë¦¬ë·°ë¥¼ ì œê³µí•˜ì„¸ìš”:
        
        1. ì‹œê°ì  ì¼ê´€ì„± ë° ë””ìì¸ ì‹œìŠ¤í…œ ì¤€ìˆ˜ ì—¬ë¶€
        2. ì‚¬ìš©ì ê²½í—˜ ë° ìƒí˜¸ì‘ìš© íë¦„
        3. ì ‘ê·¼ì„± ë° í¬ìš©ì„±
        4. ê°œì„  ì œì•ˆ
        
        ê°ê´€ì ì´ê³  ê±´ì„¤ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”.
        """
        
        prompt = f"""
        í˜„ì¬ ë””ìì¸ ì‹œìŠ¤í…œ:
        {json.dumps(self.design_system, indent=2, ensure_ascii=False)}
        
        ì‘ì—… ìš”ì²­: {task_desc}
        
        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ë””ìì¸ ë¦¬ë·°ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
        """
        
        return self._call_ollama_api(prompt, system_prompt, temperature=0.6, max_tokens=1500)
    
    def _handle_general_design_task(self, task_desc: str) -> str:
        """
        ì¼ë°˜ ë””ìì¸ ê´€ë ¨ ì‘ì—… ì²˜ë¦¬
        
        Args:
            task_desc: ì‘ì—… ì„¤ëª…
            
        Returns:
            str: ì‘ì—… ê²°ê³¼
        """
        system_prompt = """
        ë‹¹ì‹ ì€ UI/UX ë””ìì´ë„ˆì…ë‹ˆë‹¤. ë””ìì¸ ê´€ë ¨ ì§ˆë¬¸ì´ë‚˜ ìš”ì²­ì— ëª…í™•í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
        ê°€ëŠ¥í•œ ê²½ìš° ë‹¤ì–‘í•œ ë””ìì¸ ì˜µì…˜ê³¼ ê° ì˜µì…˜ì˜ ì¥ë‹¨ì ì„ ì œì‹œí•˜ì„¸ìš”.
        í•„ìš”ì— ë”°ë¼ íŠ¸ë Œë“œ, ëª¨ë²” ì‚¬ë¡€, ë””ìì¸ ì›ì¹™ ë“±ì„ ì–¸ê¸‰í•˜ì„¸ìš”.
        """
        
        prompt = f"""
        í˜„ì¬ ë””ìì¸ ì‹œìŠ¤í…œ:
        {json.dumps(self.design_system, indent=2, ensure_ascii=False)}
        
        ì‘ì—… ìš”ì²­: {task_desc}
        
        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """
        
        return self._call_ollama_api(prompt, system_prompt, temperature=0.7, max_tokens=1500)
    
    def update_design_system(self, updates: Dict[str, Any]) -> Dict[str, Any]:
        """
        ë””ìì¸ ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
        
        Args:
            updates: ì—…ë°ì´íŠ¸í•  ë””ìì¸ ì‹œìŠ¤í…œ ìš”ì†Œ
            
        Returns:
            Dict[str, Any]: ì—…ë°ì´íŠ¸ëœ ë””ìì¸ ì‹œìŠ¤í…œ
        """
        # ë¶€ë¶„ ì—…ë°ì´íŠ¸ ì²˜ë¦¬
        for key, value in updates.items():
            if key in self.design_system and isinstance(value, dict):
                self.design_system[key].update(value)
            else:
                self.design_system[key] = value
        
        return self.design_system
    
    def get_design_system(self) -> Dict[str, Any]:
        """
        í˜„ì¬ ë””ìì¸ ì‹œìŠ¤í…œ ë°˜í™˜
        
        Returns:
            Dict[str, Any]: í˜„ì¬ ë””ìì¸ ì‹œìŠ¤í…œ
        """
        return self.design_system
    
    def run_task(self, task_description: str) -> str:
        """
        ì‘ì—… ì‹¤í–‰ (í˜¸í™˜ì„±ì„ ìœ„í•œ ë©”ì„œë“œ)
        
        Args:
            task_description: ì‘ì—… ì„¤ëª…
            
        Returns:
            str: ì‘ì—… ê²°ê³¼
        """
        return self._run({"task": task_description})

# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    # Ollama Designer ì—ì´ì „íŠ¸ ìƒì„±
    agent = DesignerAgentOllama(
        api_base="http://localhost:11434/api",
        model="llama3.2:latest"
    )
    
    # í…ŒìŠ¤íŠ¸ ì‘ì—…
    test_tasks = [
        "ë¡œê·¸ì¸ í˜ì´ì§€ ì™€ì´ì–´í”„ë ˆì„ì„ ì‘ì„±í•´ì£¼ì„¸ìš”",
        "ë©”ì¸ ìƒ‰ìƒ íŒ”ë ˆíŠ¸ì— ì¤‘ê°„ ê°•ì¡°ìƒ‰ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”",
        "ì…ë ¥ í•„ë“œ ì»´í¬ë„ŒíŠ¸ë¥¼ ë””ìì¸í•´ì£¼ì„¸ìš”"
    ]
    
    for task in test_tasks:
        print(f"=== ì‘ì—…: {task} ===")
        result = agent.run_task(task)
        print(f"ê²°ê³¼ (ì¼ë¶€): {result[:150]}...\n")
    
    # ë””ìì¸ ì‹œìŠ¤í…œ ì¶œë ¥
    print("=== ë””ìì¸ ì‹œìŠ¤í…œ ===")
    print(json.dumps(agent.get_design_system(), indent=2, ensure_ascii=False)) 